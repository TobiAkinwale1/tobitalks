{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In the land of code where logic reigns,  \\nA curious tale of recursion remains.  \\nA function calls itself, a playful dance,  \\nIn a loop of thought, it takes a chance.  \\n\\nLike a mirror reflecting a mirror\\'s gaze,  \\nEach call, a layer in a thoughtful maze.  \\n\"Dear function,\" it whispers, \"come join the fun,\"  \\n\"I\\'ll send you a task when your first one is done.\"  \\n\\n\"Divide and conquer,\" the wise ones say,  \\nBreak problems to parts, chart a clearer way.  \\nBut heed the base case, that guiding light,  \\nFor without an endpoint, you\\'ll spiral from sight.  \\n\\nImagine a tale of a ten-story tower,  \\nWhere each floor needs cleaning, a tedious hour.  \\nStart at the top, let the function descend,  \\nCleaning each floor, till it reaches the end.  \\n\\n\"Clean me,\" cries floor ten, but just wait a while,  \\nFor floor nine needs touching with each recursive smile.  \\nSo the function calls back, down the floors it goes,  \\nEach call stacking up like a well-placed rose.  \\n\\nAt the base, it gases with a gentle sigh,  \\n\"Floor one is clean!\" then it starts to fly.  \\nNow back through the stories in reverse it must weave,  \\nCompleting the task that it once did conceive.  \\n\\nWith each step returning, the journey unfolds,  \\nRecursion, a dance with infinite folds.  \\nSo remember this lesson in code that you write,  \\nWith a base case in sight, recursion takes flight.  \\n\\nIn the grand tapestry of logic and rhyme,  \\nEmbrace recursionâ€”it saves you great time!  \\nLike echoes in valleys, each call sings clear,  \\nIn the world of programming, recursion brings cheer!  ', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Tobi, a knowledgeable assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/components/chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ChatInterface.__init__() got an unexpected keyword argument 'retry_btn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m               partial_message \u001b[38;5;241m=\u001b[39m partial_message \u001b[38;5;241m+\u001b[39m chunk\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     32\u001b[0m               \u001b[38;5;28;01myield\u001b[39;00m partial_message\n\u001b[0;32m---> 35\u001b[0m gr\u001b[38;5;241m.\u001b[39mChatInterface(\n\u001b[1;32m     36\u001b[0m     predict,\n\u001b[1;32m     37\u001b[0m     chatbot\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mChatbot(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m     38\u001b[0m     textbox\u001b[38;5;241m=\u001b[39mgr\u001b[38;5;241m.\u001b[39mTextbox(placeholder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsk me a yes or no question\u001b[39m\u001b[38;5;124m\"\u001b[39m, container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m     39\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTobi-Talks\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsk me anytin wey dey your mind\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     theme\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaleyCH/HaleyCH_Theme\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     examples\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow you dey\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWetin dey for your side?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou get tips for business?\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     43\u001b[0m     cache_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m     retry_btn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m     undo_btn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelete Previous\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     clear_btn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m )\u001b[38;5;241m.\u001b[39mlaunch(share\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ChatInterface.__init__() got an unexpected keyword argument 'retry_btn'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "with open('public/knowledge.json', 'r') as file:\n",
    "    knowledge_data = json.load(file)\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def predict(message, history):\n",
    "    knowledge_content = json.dumps(knowledge_data)\n",
    "    system_message = {\"role\": \"system\", \"content\": f\"You are a helpful assistant named Tobi. sometimes you answer the questions in pidgin english. Here is some additional knowledge: {knowledge_content}\"}\n",
    "    history_openai_format = [system_message]\n",
    "    for human, assistant in history:\n",
    "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
    "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
    "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "  \n",
    "    response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "    messages= history_openai_format,\n",
    "    temperature=1.0,\n",
    "    stream=True)\n",
    "\n",
    "    partial_message = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "              partial_message = partial_message + chunk.choices[0].delta.content\n",
    "              yield partial_message\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    predict,\n",
    "    chatbot=gr.Chatbot(height=500),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a yes or no question\", container=False, scale=7),\n",
    "    title=\"Tobi-Talks\",\n",
    "    description=\"Ask me anytin wey dey your mind\",\n",
    "    theme=\"HaleyCH/HaleyCH_Theme\",\n",
    "    examples=[\"How you dey\", \"Wetin dey for your side?\", \"You get tips for business?\"],\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 2016, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1569, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 28, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(func, *args, cancellable=cancellable,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 846, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/vd/lvq3x31s1xxf5zmq9tmxd3wm0000gn/T/ipykernel_35135/918326607.py\", line 14, in add_user_data\n",
      "    user_data = user_data.append({\"Name\": name, \"Score\": score}, ignore_index=True)\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tobivalentine/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\", line 5989, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'append'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store user data\n",
    "user_data = pd.DataFrame(columns=[\"Name\", \"Score\"])\n",
    "\n",
    "# Function to add user's name and score to the DataFrame and display it\n",
    "def add_user_data(name):\n",
    "    global user_data\n",
    "    # Example score calculation (you can replace this with your quiz scoring logic)\n",
    "    score = 0  # Assume score is initially zero or fetch from a scoring mechanism\n",
    "    \n",
    "    # Append user data to the DataFrame\n",
    "    user_data = user_data.append({\"Name\": name, \"Score\": score}, ignore_index=True)\n",
    "    \n",
    "    # Return the updated DataFrame\n",
    "    return user_data\n",
    "\n",
    "# Set up the Gradio interface with the latest component syntax\n",
    "app = gr.Interface(\n",
    "    fn=add_user_data,\n",
    "    inputs=gr.Textbox(label=\"Enter your name\"),\n",
    "    outputs=gr.Dataframe(label=\"User Data Table\")\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store user data\n",
    "user_data = pd.DataFrame(columns=[\"Name\", \"Score\"])\n",
    "\n",
    "# Function to add user's name and score to the DataFrame and display it\n",
    "def add_user_data(name):\n",
    "    global user_data\n",
    "    # Example score calculation (you can replace this with your quiz scoring logic)\n",
    "    score = 0  # Assume score is initially zero or fetch from a scoring mechanism\n",
    "    \n",
    "    # Create a new row as a DataFrame\n",
    "    new_row = pd.DataFrame({\"Name\": [name], \"Score\": [score]})\n",
    "    \n",
    "    # Use pd.concat to add the new row to the existing DataFrame\n",
    "    user_data = pd.concat([user_data, new_row], ignore_index=True)\n",
    "    \n",
    "    # Return the updated DataFrame\n",
    "    return user_data\n",
    "\n",
    "# Set up the Gradio interface with the latest component syntax\n",
    "app = gr.Interface(\n",
    "    fn=add_user_data,\n",
    "    inputs=gr.Textbox(label=\"Enter your name\"),\n",
    "    outputs=gr.Dataframe(label=\"Table\")\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
